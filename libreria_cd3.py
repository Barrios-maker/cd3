# -*- coding: utf-8 -*-
"""Libreria_CD3

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t_qBKjqHIwXarcKKkEA04Z_YzV4WRnv1
"""

import numpy as np

class ResumenNumerico:

  def __init__(self, datos):
    self.datos = list(datos)

  def calculo_de_media(self):
    s = 0
    for i in self.datos:
      s += i
    media = s/len(self.datos)
    return media

  def calculo_de_mediana(self):
    datos = np.array(self.datos)
    mediana = np.median(datos)
    return mediana

  def calculo_de_desvio_estandar(self):
    m = self.calculo_de_media()
    desvio_estandar = ((sum([(i-m)**2 for i in self.datos]))/len(self.datos))**0.5
    return desvio_estandar

  def calculo_de_cuartiles(self):
    datos_ordenados = sorted(np.array(self.datos))

    q1 = np.percentile(datos_ordenados,25)
    q2 = np.percentile(datos_ordenados,50)
    q3 = np.percentile(datos_ordenados,75)

    return [q1, q2, q3]

  def generacion_resumen_numerico(self):
    res_num = {
    'Media': self.calculo_de_media(),
    'Mediana': self.calculo_de_mediana(),
    'Desvio': self.calculo_de_desvio_estandar(),
    'Cuartiles': self.calculo_de_cuartiles(),
    'Mínimo': min(self.datos),
    'Máximo': max(self.datos)
    }

    return res_num

  def muestra_resumen(self):
    res_num = self.generacion_resumen_numerico()
    for estad, valor in res_num.items():
      print(f"{estad}: {np.round(valor,3)}")

from scipy.stats import norm


class ResumenGrafico:

  def __init__(self,datos):
    self.datos = np.array(datos)

  def generacion_del_histograma(self,h):
    val_min = min(self.datos)
    val_max = max(self.datos)
    bins = np.arange(val_min, val_max, h)
    if bins[-1] < val_max :
      np.append(bins, bins[-1] + h )

    m = len(bins)
    alturas = [0 for i in range(m-1)]
    for i in self.datos:
      for j in range(len(bins)-1):
        if i == bins[0]:
          alturas[0] += 1
          break
        elif bins[j] < i < bins[j+1]:
          alturas[j] += 1
          break
    for i in range(len(alturas)):
      alturas[i] /= (len(self.datos) * h)

    return bins, alturas

  def generar_datos_normales(media,desvio,n):
    return np.random.normal(media,desvio,n)

  def generar_datos_BS(media, desvio, n):
    u = np.random.uniform(size=(n,))
    y = u.copy()
    ind = np.where(u > 0.5)[0]
    y[ind] = np.random.normal(media, desvio, size=len(ind))
    for j in range(5):
        ind = np.where((u > j * 0.1) & (u <= (j+1) * 0.1))[0]
        y[ind] = np.random.normal(j/2 - 1, 1/10, size=len(ind))
    return y

  def evaluar_histograma(self,h,x):
    bins, alturas = self.generacion_del_histograma(h)
    res = [0 for i in range(len(x))]

    for j in range(len(x)):
      if x[j] == min(self.datos):
        res[j] == alturas[0]
      else:
        for i in range(len(bins)-1):
          if bins[i]<x[j]<=bins[i+1]:
            res[j]=alturas[i]
            break
    return res

# --------Distribuciones--------
  def gaussiano(x):
    valor_kernel_gaussiano = np.exp(-(np.power(x,2))/2)/(np.sqrt(np.pi*2))
    return valor_kernel_gaussiano

  def uniforme (x):
    valor_kernel_uniforme = 0
    if -1/2 <= x < 1/2:
      valor_kernel_uniforme = 1
    return valor_kernel_uniforme

  def triangular(x):
    if -1<=x<0:
      return 1+x
    elif 0<=x<1:
      return 1-x
    else:
      return 0


  def cuadratico(x):
    if -1 <= x < 1:
      return 3/4*(1-np.power(x,2))
    else:
      return 0

# ------------------------------

  def estimar_densidad(self,x,h,kernel=uniforme):
    frecuencia = 0
    for i in self.datos:
      frecuencia += kernel((x-i)/h)
    return frecuencia/(len(self.datos)*h)

import pandas as pd
import matplotlib.pyplot as plt

class Regresion():
  def __init__(self,X,y,Xt=None,yt = None):
    self.predictoras = pd.DataFrame(X)
    self.respuesta = y
    self.predictoras_t = pd.DataFrame(Xt)
    self.respuesta_t = yt

  def Grafica(self):
    self.ajustar()
    if self.predictoras.shape[1] != 1:
      return None
    else:
      plt.scatter(self.predictoras,self.respuesta, color = 'green', label = 'Datos')
      plt.plot(self.predictoras,self.curva_ajustada, color = 'black', label = 'Ajuste')
      plt.legend()

  def ECM(self):
    self.ajustar()
    dif = [self.curva_ajustada[i] - self.respuesta[i] for i in range(self.predictoras.shape[0])]
    return np.norm(dif)


from scipy.stats import t

class RegresionLinealSimple(Regresion):

  def __init__(self,datosx,datosy,datosx_t = None,datosy_t = None):
    super().__init__(datosx,datosy,datosx_t,datosy_t)
    self.datosx = np.array(datosx)
    self.datosy = np.array(datosy)
    self.len = len(datosx)

  def estimacion_betas(self):
    mediax = np.mean(self.datosx)
    mediay = np.mean(self.datosy)
    num = sum([(self.datosx[i] - mediax)*(self.datosy[i]-mediay) for i in range(self.len)])
    denom = sum([(self.datosx[i]-mediax)**2 for i in range(self.len)])

    b1 = num/denom
    b0 = mediay - b1*mediax

    setattr(self,'parametros',[b0,b1])
    return self.parametros

  def ajustar(self):
    self.estimacion_betas()
    b0 = self.parametros[0]
    b1 = self.parametros[1]
    y_teorico = [b0 +b1*i for i in self.datosx]
    setattr(self,'curva_ajustada',y_teorico)


  def residuos(self):
    self.estimacion_betas()
    b0 = self.parametros[0]
    b1 = self.parametros[1]
    r = [self.datosy[i]-(b0 + b1*self.datosx[i]) for i in range(self.len)]
    setattr(self,'res',r)
    return r

  def desvio(self):
    self.residuos()
    r = self.res
    return sum([i**2 for i in r])/(self.len-2)

  def analisis_residuos(self):
    r = self.residuos()
    r_std = sorted((r-np.mean(r))/np.std(r))
    r_teoricos = norm.ppf([(0.5+i)/(self.len) for i in range(self.len)])
    plt.scatter(r_teoricos,r_std, color = 'blue', marker = 'o')
    plt.plot(r_teoricos,r_teoricos, color = 'red')
    plt.show()
    plt.scatter(self.datosx,r)
    plt.show()

  def predecir(self,x_nuevo,alpha = 0.05, IC = True):
    self.estimacion_betas()
    b0 = self.parametros[0]
    b1 = self.parametros[1]
    prediccion = b0 +b1*x_nuevo
    desvio = self.desvio()

    if IC:
      var_b1=desvio/(sum((self.datosx-np.mean(self.datosx))**2))
      var_b0=desvio*np.sum(self.datosx**2)/(self.len*sum((self.datosx-np.mean(self.datosx))**2))
      cov_01=-np.mean(self.datosx)*desvio/sum((self.datosx-np.mean(self.datosx))**2)
      SE2=var_b0+(x_nuevo**2)*var_b1+2*x_nuevo*cov_01
      SE = np.sqrt(SE2)
      IC = [prediccion + t.ppf(alpha/2, self.len-2)*SE, prediccion - t.ppf(alpha/2, self.len-2)*SE]
      print('Prediccion: ', prediccion,'\n',' Intervalo de confianza del '+str((1-alpha)*100)+ ' % :', IC)
    else:
      return prediccion


  def testear(self):
    X = self.predictoras_t
    predicciones = []
    for i in X:
      predicciones.append(self.predecir(i, IC = False))

    dif = [predicciones[i] - self.respuesta_t[i] for i in range(len(predicciones))]

    return('ECM = '+str(round(np.linalg.norm(dif),3)))



import statsmodels.api as sm


import numpy as np

class RegresionLinealMultiple():
    def __init__(self,x,y):
        self.x = x
        self.y = y
        self.model = None
        self.results = None

    def ajustar(self):
        X = sm.add_constant(self.x)
        self.model = sm.OLS(self.y, X)
        self.results = self.model.fit()

    def predecir(self):
        self.ajustar()
        X = sm.add_constant(self.x)
        return self.results.predict(X)

    def betas(self):
        return self.results.params[1:]

    def intercepcion(self):
        return self.results.params[0]




class RegresionLogistica(Regresion):
  def __init__(self,X,y,Xt = None, yt = None):
    super().__init__(X,y,Xt,yt)
    self.predictoras = pd.DataFrame(X)
    self.respuesta = y
    self.desvios = None

  def proba(self,L_var):
    L_var = np.array(L_var)
    L_var = np.insert(L_var,0,1)
    termino_lineal = np.dot(self.parametros,L_var)
    l = np.exp(termino_lineal)/(1+np.exp(termino_lineal))
    return l

  def ajustar(self):
    matriz_diseño = sm.add_constant(self.predictoras)
    modelo = sm.Logit(self.respuesta,matriz_diseño)
    resultado = modelo.fit()
    setattr(self,'parametros', resultado.params)

    if self.predictoras.shape[1] == 1:
      dominio = np.linspace(min(self.predictoras[0]),max(self.predictoras[0]),self.predictoras.shape[0])
      crv_aj = [self.proba(i) for i in dominio]
      setattr(self,'curva_ajustada', crv_aj)

  def testear(self,pc = 0.5):
    X = pd.DataFrame(self.predictoras_t)
    y = self.respuesta_t
    n_test = len(self.predictoras_t)

    #self.ajustar()

    y_logistica = [self.proba(X.loc[i]) for i in range(X.shape[0])]
    y_pred = [int(y_logistica[i] >= pc) for i in range(X.shape[0])]


    # Tabla de confucion

    Y_Y = [(y_pred[i] == 1) and (y[i] == 1) for i in range(n_test)]
    N_Y = [(y_pred[i] == 0) and (y[i] == 1) for i in range(n_test)]
    Y_N = [(y_pred[i] == 1) and (y[i] == 0) for i in range(n_test)]
    N_N = [(y_pred[i] == 0) and (y[i] == 0) for i in range(n_test)]

    tabla =  pd.DataFrame({
    'y_test=1': [sum(Y_Y), sum(N_Y)],
    'y_test=0': [sum(Y_N), sum(N_N)],

    }, index=['y_pred=1', 'y_pred=0'])

    setattr(self,'Tabla',tabla)

    especificidad = tabla['y_test=0'][1]/(tabla['y_test=0'][1]+tabla['y_test=0'][0])
    sensibilidad = tabla['y_test=1'][0]/(tabla['y_test=1'][1]+tabla['y_test=1'][0])

    setattr(self,'Especificidad',especificidad)
    setattr(self,'Sensibilidad',sensibilidad)



  def Ajustar_pc(self,precision = 100, graficos = False):
    p = np.linspace(0,1,precision)
    especificidades = []
    sensibilidades = []
    for i in p:
      pred = self.testear(i)
      especificidades.append(self.Especificidad)
      sensibilidades.append(self.Sensibilidad)

    aux = [sensibilidades[i]+especificidades[i]-1 for i in range(len(p))]
    for i in range(len(aux)):
      youden = 0
      if aux[i] == max(aux):
        youden = p[i]
        break

    self.testear(pc = youden)
    setattr(self,'Youden',youden)

    if graficos:
      plt.plot(p,[sensibilidades[i]+especificidades[i]-1 for i in range(len(p))], color = 'black', label = 'Youden = ' +str(round(youden,4)))
      plt.plot([youden], [max(aux)], color = 'red')
      plt.scatter(p,especificidades, color = 'coral', label = 'especificidad')
      plt.scatter(p,sensibilidades, color = 'skyblue', label = 'sensibilidad')
      plt.legend()



  def tabla(self):
    return self.tabla

from scipy.stats import chi2


class TestDeBondad():
  """
  Test de hipotesis:
  H_0 = La muestra sigue la distribucion de probabilidad
  H_1 = La muestra no sigue la distribucion de probabilidad

  """
  def __init__(self,prob,muestra):
    self.prob = prob
    self.muestra = muestra
    self.n = sum(muestra)

  def testear(self,alpha = 0.05):
    esperados = [self.prob[i]*self.n for i in range(len(self.muestra))]

    Z_obs = sum([((esperados[i]-self.muestra[i])**2)/esperados[i] for i in range(len(self.prob))])
    df = len(self.prob)-1

    Z_crit = chi2.ppf(1-alpha,df)

    print('Z observado:',Z_obs,'Z critico:',Z_crit,'\n')

    p_valor = chi2.sf(Z_obs,df)

    print('p-valor:',p_valor,'\n')

    if p_valor < alpha:
      print('Se rechaza H0 \n')
      print('Podemos estar mas de un '+str((1-alpha)*100)+'% seguros de que la muestra no sigue la distribucion')
    else:
      print('No se puede rechazar H0 con un nivel del '+str(alpha*100)+'% de significancia \n')
      print('No me atreveria a negar que la muestra en efecto siga la distribucion de probabilidad')